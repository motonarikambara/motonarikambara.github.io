<!DOCTYPE html>
<html lang="ja">
  <head>
  	<meta charset="utf-8">
  	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
  	<meta name="description" content="">
  	<meta name="author"      content="map[]">
    
    	<title>Publications</title>
	<link rel="shortcut icon" href="https://motonarikambara.github.io/images/gt_favicon.png">

	
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	
	
	<script defer src="https://use.fontawesome.com/releases/v5.0.11/js/all.js" integrity="sha384-ImVoB8Er8knetgQakxuBS4G3RSkyD8IZVVQCAnmRJrDwqJFYUE4YOv+DbIofcO9C" crossorigin="anonymous"></script>
	
	
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	
	
  
  <link rel="stylesheet" href="https://motonarikambara.github.io/css/styles.min.64a6643395c6bf1ec6fff31d6429046b3ad467e58a279ff252dc019edd80a87051cf90b7fe2d589277def72d84602dcbc7115e2e17a94db3a8838336986a0ae3.css" integrity="sha512-ZKZkM5XGvx7G//MdZCkEazrUZ&#43;WKJ5/yUtwBnt2AqHBRz5C3/i1Yknfe9y2EYC3LxxFeLhepTbOog4M2mGoK4w==">

   
  

  </head>
  
  <body class="home">

    
      <header id="header">
  <div id="head" class="parallax" data-parallax-speed="2" style="background-image:url('https://motonarikambara.github.io/images/bg.webp');">
    <h1 id="logo" class="text-center">
      <img class='img-circle' src="https://motonarikambara.github.io/images/head.png" alt="">
      <span class="title">Motonari Kambara</span>
      <span class="tagline"><br>
        <a href="mailto:"></a>
      </span>
   </h1>
</div>

<nav class="navbar navbar-default navbar-sticky">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="true">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav">
            
                
                <li>
                    <a href="/">home</a>
                </li>
                
            
                
                <li>
                    <a href="/profile/">Profile</a>
                </li>
                
            
                
                <li>
                    <a href="/publications/">Publications</a>
                </li>
                
            
            </ul>

        </div>
        
    </div>
</nav>

</header>
    
 
    
<main id="main">

	<div class="container">
		<div class="row topspace">
			<div class="col-sm-8 col-sm-offset-2">

        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/journal/" rel="bookmark">Journal</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>T. Komatsu, M. Kambara, S. Hatanaka, H. Matsuo, T. Hirakawa, T. Yamashita, H. Fujiyoshi, and K. Sugiura, “Nearest Neighbor Future Captioning: Generating Descriptions for Possible Collisions in Object Placement Tasks”, Advanced Robotics, Vol. 38, Issue 18, pp. 1265-1276, 2024. DOI: 10.1080/01691864.2024.2388114. <a href="https://web3.arxiv.org/pdf/2407.13186">PDF</a></li>
<li>K. Kaneda, S. Nagashima, R. Korekata, M. Kambara, and K. Sugiura, “Learning-To-Rank Approach for Identifying Everyday Objects Using a Physical-World Search Engine”, IEEE Robotics and Automation Letters, Vol. 9, Issue 3, pp. 2088-2095, 2024. DOI: 10.1109/LRA.2024.3352363. <a href="https://arxiv.org/pdf/2312.15844">PDF</a></li>
<li>M. Kambara and K. Sugiura, “Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions”, IEEE Robotics and Automation Letters, Vol. 6, Issue 4, pp. 8371-8378, 2021. DOI: 10.1109/LRA.2021.3107026. <a href="https://arxiv.org/pdf/2107.00789.pdf">PDF</a></li>
</ol>

					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/inter_conf/" rel="bookmark">International Conference</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>M. Goko*, M. Kambara*, S. Otsuki, D. Saito, and K. Sugiura (*: Equal contribution), “Task Success Prediction for Open-Vocabulary Manipulation Based on Multi-Level Aligned Representations”, CoRL, 2024. <a href="https://5ei74r0.github.io/contrastive-lambda-repformer.page/">project page</a>, <a href="https://openreview.net/pdf?id=QtCtY8zl2T">PDF</a></li>
<li>K. Kaneda, S. Nagashima, R. Korekata, M. Kambara, and K. Sugiura, “Learning-To-Rank Approach for Identifying Everyday Objects Using a Physical-World Search Engine”, IEEE RAL presented at IEEE/RSJ IROS, 2024.</li>
<li>T. Nishimura, K. Kuyo, M. Kambara, and K. Sugiura, “Object Segmentation from Open-Vocabulary Manipulation Instructions Based on Optimal Transport Polygon Matching with Multimodal Foundation Models”, IEEE/RSJ IROS, 2024. <a href="https://arxiv.org/pdf/2407.00985">PDF</a></li>
<li>M. Kambara, C. Hori, K. Sugiura, K. Ota, D. K Jha, S. Khurana, S. Jain, R. Corcodel, D. Romeres, J. L. Roux, &ldquo;Human Action Understanding-based Robot Planning using Multimodal LLM&rdquo;, ICRA 2024 Cooking Robotics Workshop, 2024. <a href="https://www.merl.com/publications/docs/TR2024-066.pdf">PDF</a></li>
<li>R. Korekata, M. Kambara, Y. Yoshida, S. Ishikawa, Y. Kawasaki, M. Takahashi and K. Sugiura, “Switching Head–Tail Funnel UNITER for Dual Referring Expression Comprehension with Fetch-and-Carry Tasks”, IEEE/RSJ IROS, 2023. <a href="https://arxiv.org/pdf/2307.07166.pdf">PDF</a></li>
<li>K. Kaneda, R. Korekata, Y. Wada, S. Nagashima, M. Kambara, Y. Iioka, H. Matsuo, Y. Imai, T. Nishimura, and K. Sugiura, “DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial Training”, CVPR 2023 Embodied AI Workshop, 2023. <a href="https://embodied-ai.org/papers/2023/23.pdf">PDF</a></li>
<li>M. Kambara and K. Sugiura, “Fully Automated Task Management for Generation, Execution, and Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language Instructions in Continuous Space”, CVPR 2023 Embodied AI Workshop, 2023. <a href="https://embodied-ai.org/papers/2023/6.pdf">PDF</a></li>
<li>M. Kambara, K.Sugiura, “Relational Future Captioning Model for Explaining Likely Collisions in Daily Tasks”, IEEE ICIP, TP-V2.V13.14, 2022. <a href="https://arxiv.org/pdf/2207.09083.pdf">PDF</a></li>
<li>M. Kambara and K. Sugiura, “Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions”, IEEE RAL presented at IEEE/RSJ IROS, 2021. <a href="https://arxiv.org/pdf/2107.00789.pdf">PDF</a></li>
</ol>

					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/award/" rel="bookmark">Award</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>K. Kaneda, R. Korekata, Y. Wada, S. Nagashima, M. Kambara, Y. Iioka, H. Matsuo, Y. Imai, T. Nishimura, K. Sugiura, CVPR 2023 Embodied AI Workshop DialFRED Challenge 1st Prize, 6/19/2023.</li>
<li>M. Kambara, Y. Yoshida, K. Kaneda, S. Otsuki, R. Korekata, H. Matsuo, Y. Wada, W. Yang, K. Sugiura, Honorable Mention Award, REVERIE Challenge @ CSIG 2022, 8/19/2022.</li>
</ol>

					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/domestic_conf/" rel="bookmark">Domestic Conference</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>松尾榛夏, 神原元就, 杉浦孔明: “マルチモーダル基盤モデルと劣モジュラ最適化に基づく移動ロボットの環境探索”, 2024年度 人工知能学会全国大会, 4O3-OS-16e-03, 2024.</li>
<li>齋藤大地, 神原元就, 九曜克之, 杉浦孔明: “マルチモーダルLLMおよび視覚言語基盤モデルに基づく大規模物体操作データセットにおけるタスク成功判定”, 2024年度 人工知能学会全国大会, 3O1-OS-16b-02, 2024.</li>
<li>西村喬行, 九曜克之, 神原元就, 杉浦孔明: “マルチモーダル基盤モデルと最適輸送を用いたポリゴンマッチングによる参照表現セグメンテーション”, 2024年度 人工知能学会全国大会, 2O6-OS-16a-02, 2024.</li>
<li>平野慎之助, 小松拓実, 和田唯我, 神原元就, 畑中駿平, 平川翼, 山下隆義, 藤吉弘亘, 杉浦孔明: “ENCHANT: 大規模言語モデルを用いた仮説生成に基づくクロスモーダル説明文生成”, 第41回日本ロボット学会学術講演会, 1K4-03, 2023.</li>
<li>神原元就, 杉浦孔明: “マルチモーダル言語処理に基づくfetch-and-carryタスクの自動化と実行”, 2023年度 人工知能学会全国大会, 2I6-OS-4a-03, 2023.</li>
<li>兼田寛大, 神原元就, 杉浦孔明: “Learning to Rank Physical Objects: ランキング学習による物理世界検索エンジン”, 2023年度 人工知能学会全国大会, 3G1-OS-24a-01, 2023.</li>
<li>小松拓実, 神原元就, 畑中駿平, 松尾榛夏, 平川翼, 山下隆義, 藤吉弘亘, 杉浦孔明: “Nearest Neighbor Future Captioning:物体配置タスクにおける衝突リスクに関する説明文生成”, 2023年度 人工知能学会全国大会, 3G1-OS-24a-05, 2023.</li>
<li>是方諒介, 神原元就, 吉田悠, 石川慎太朗, 川崎陽祐, 髙橋正樹, 杉浦孔明: “Switching Head–Tail Funnel UNITERによる対象物体および配置目標に関する指示文理解と物体操作”, 2023年度 人工知能学会全国大会, 2G4-OS-21d-01, 2023.</li>
<li>神原元就, 杉浦孔明: “記号接地されたfetch-and-carryタスクの自動化と実行”, 第40回日本ロボット学会学術講演会, 4I1-01, 2022.</li>
<li>飯岡雄偉, 神原元就, 杉浦孔明: “物体配置タスクにおける危険性のクロスモーダル説明生成”, 第40回日本ロボット学会学術講演会, 4I1-08, 2022.</li>
<li>神原元就, 杉浦孔明: “日常タスクにおける将来イベントのクロスモーダル説明文生成”, 2022年度 人工知能学会全国大会, 2O1-GS-7-02, 2022.</li>
<li>神原元就, 杉浦孔明: “料理タスクにおける将来イベントのクロスモーダル説明文生成”, 第28回画像センシングシンポジウム 2022, SO3-24・IS3-24, 2022.</li>
<li>兼田寛大, 神原元就, 杉浦孔明: “Bilingual Case Relation Transformerに基づく複数言語による物体操作指示文生成”, 第39回日本ロボット学会学術講演会, 1I2-06, 2021.</li>
<li>神原元就, 杉浦孔明: “Case Relation Transformerに基づく対象物体及び目標領域の参照表現を含む物体操作指示文生成”, 2021年度 人工知能学会全国大会, 4J1-GS-6d-05, 2021.</li>
</ol>

					</div>
				</article>
        
			</div>
		</div>

		<center class="">
			<ul class="pagination">
        
			</ul>
		</center>
	</div>	

</main>

    
    
      <footer id="footer">
	<div class="container">
		<div class="row">
			
			<div class="col-md-3 widget">
				<h3 class="widget-title"></h3>
				<div class="widget-body">
					<p>
					
					<br>
					
					</p>
				</div>
			</div>
			

			
			<div class="col-md-3 widget">
				<h3 class="widget-title"></h3>
				<div class="widget-body">
					<p class="follow-me-icons">
            
							
								<a href="https://twitter.com/MotonariKambara" target="_blank"><i class="fab fa-x-twitter fa-1x"></i></a>
							
            
							
								<a href="https://jp.linkedin.com/in/motonari-kambara-3a9330280" target="_blank"><i class="fab fa-linkedin fa-1x"></i></a>
							
            
							
								<a href="https://github.com/motonarikambara" target="_blank"><i class="fab fa-github fa-1x"></i></a>
							
            
							
								<a href="motonari.k714@keio.jp" target="_blank"><i class="fas fa-envelope fa-1x"></i></a>
							
            
					</p>
				</div>
			</div>
			

			

			

		</div> 
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p></p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
                                                
                                                Copyright &copy; , Motonari Kambara<br>
                                                
						Design: <a href="http://www.gettemplate.com" rel="designer">Initio by GetTemplate</a> -
						Powered by: <a href="https://gohugo.io/" rel="poweredby">Hugo</a>
					</p>
				</div>
			</div>

		</div> 
	</div>
</footer>




<script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>




<script src="https://motonarikambara.github.io/js/bundle.min.8adc00f11fb328590a42ed3b14d3ec5b116abb98395a8a662d782f2150a7de6cc85eacb26c14724bb0c5130a11be2933c9b4f835cd3a053e90f036e210fbdd5d.js" integrity="sha512-itwA8R&#43;zKFkKQu07FNPsWxFqu5g5WopmLXgvIVCn3mzIXqyybBRyS7DFEwoRvikzybT4Nc06BT6Q8DbiEPvdXQ=="></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-3R7Q5YFDBK', 'auto');
  ga('send', 'pageview');
</script>

</body>
</html>

    
  </body>
  
</html>