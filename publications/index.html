<!DOCTYPE html>
<html lang="ja">
  <head>
  	<meta charset="utf-8">
  	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
  	<meta name="description" content="">
  	<meta name="author"      content="map[]">
    
    	<title>Publications</title>
	<link rel="shortcut icon" href="https://motonarikambara.github.io/images/gt_favicon.png">

	
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	
	
	<script defer src="https://use.fontawesome.com/releases/v5.0.11/js/all.js" integrity="sha384-ImVoB8Er8knetgQakxuBS4G3RSkyD8IZVVQCAnmRJrDwqJFYUE4YOv+DbIofcO9C" crossorigin="anonymous"></script>
	
	
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	
	
  
  <link rel="stylesheet" href="https://motonarikambara.github.io/css/styles.min.64a6643395c6bf1ec6fff31d6429046b3ad467e58a279ff252dc019edd80a87051cf90b7fe2d589277def72d84602dcbc7115e2e17a94db3a8838336986a0ae3.css" integrity="sha512-ZKZkM5XGvx7G//MdZCkEazrUZ&#43;WKJ5/yUtwBnt2AqHBRz5C3/i1Yknfe9y2EYC3LxxFeLhepTbOog4M2mGoK4w==">

   
  

  </head>
  
  <body class="home">

    
      <header id="header">
  <div id="head" class="parallax" data-parallax-speed="2" style="background-image:url('https://motonarikambara.github.io/images/bg.webp');">
    <h1 id="logo" class="text-center">
      <img class='img-circle' src="https://motonarikambara.github.io/images/head.png" alt="">
      <span class="title">Motonari Kambara</span>
      <span class="tagline"><br>
        <a href="mailto:"></a>
      </span>
   </h1>
</div>

<nav class="navbar navbar-default navbar-sticky">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="true">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav">
            
                
                <li>
                    <a href="/">home</a>
                </li>
                
            
                
                <li>
                    <a href="/profile/">Profile</a>
                </li>
                
            
                
                <li>
                    <a href="/publications/">Publications</a>
                </li>
                
            
            </ul>

        </div>
        
    </div>
</nav>

</header>
    
 
    
<main id="main">

	<div class="container">
		<div class="row topspace">
			<div class="col-sm-8 col-sm-offset-2">

        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/journal/" rel="bookmark">Journal</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>M. Kambara and K. Suigura, &ldquo;Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models&rdquo;, Advanced Robotics, Vol. 39, Issue 13, pp. 806–816, 2025. DOI: 10.1080/01691864.2025.2532610. <a href="https://arxiv.org/abs/2509.13839">PDF</a></li>
<li>K. Katsumata, M. Kambara, D. Yashima, R. Korekata, and K. Sugiura, “Mobile Manipulation Instruction Generation from Multiple Images with Automatic Metric Enhancement”, IEEE Robotics and Automation Letters, Vol. 10, Issue 3, pp. 3022-3029, 2025. DOI: 10.1109/LRA.2025.3539086. <a href="https://ieeexplore.ieee.org/document/10873846">PDF</a></li>
<li>T. Komatsu, M. Kambara, S. Hatanaka, H. Matsuo, T. Hirakawa, T. Yamashita, H. Fujiyoshi, and K. Sugiura, “Nearest Neighbor Future Captioning: Generating Descriptions for Possible Collisions in Object Placement Tasks”, Advanced Robotics, Vol. 38, Issue 18, pp. 1265-1276, 2024. DOI: 10.1080/01691864.2024.2388114. <a href="https://web3.arxiv.org/pdf/2407.13186">PDF</a></li>
<li>K. Kaneda, S. Nagashima, R. Korekata, M. Kambara, and K. Sugiura, “Learning-To-Rank Approach for Identifying Everyday Objects Using a Physical-World Search Engine”, IEEE Robotics and Automation Letters, Vol. 9, Issue 3, pp. 2088-2095, 2024. DOI: 10.1109/LRA.2024.3352363. <a href="https://arxiv.org/pdf/2312.15844">PDF</a></li>
<li>M. Kambara and K. Sugiura, “Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions”, IEEE Robotics and Automation Letters, Vol. 6, Issue 4, pp. 8371-8378, 2021. DOI: 10.1109/LRA.2021.3107026. <a href="https://arxiv.org/pdf/2107.00789.pdf">PDF</a></li>
</ol>

					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/inter_conf/" rel="bookmark">International Conference</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>C. Hori, M. Kambara, K. Sugiura, K. Ota, S. Khurana, S. Jain, R. Corcodel, D. Jha, D. Romeres, J. Le Roux. “Interactive Robot Action Replanning using Multimodal LLM Trained from Human Demonstration Videos”, IEEE ICASSP, pp.6390–6394, 2025. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887717">PDF</a></li>
<li>M. Goko*, M. Kambara*, S. Otsuki, D. Saito, and K. Sugiura (*: Equal contribution), “Task Success Prediction for Open-Vocabulary Manipulation Based on Multi-Level Aligned Representations”, CoRL, 2024. <a href="https://5ei74r0.github.io/contrastive-lambda-repformer.page/">project page</a>, <a href="https://openreview.net/pdf?id=QtCtY8zl2T">PDF</a></li>
<li>K. Kaneda, S. Nagashima, R. Korekata, M. Kambara, and K. Sugiura, “Learning-To-Rank Approach for Identifying Everyday Objects Using a Physical-World Search Engine”, IEEE RAL presented at IEEE/RSJ IROS, 2024.</li>
<li>T. Nishimura, K. Kuyo, M. Kambara, and K. Sugiura, “Object Segmentation from Open-Vocabulary Manipulation Instructions Based on Optimal Transport Polygon Matching with Multimodal Foundation Models”, IEEE/RSJ IROS, 2024. <a href="https://arxiv.org/pdf/2407.00985">PDF</a></li>
<li>M. Kambara, C. Hori, K. Sugiura, K. Ota, D. K Jha, S. Khurana, S. Jain, R. Corcodel, D. Romeres, J. L. Roux, &ldquo;Human Action Understanding-based Robot Planning using Multimodal LLM&rdquo;, ICRA 2024 Cooking Robotics Workshop, 2024. <a href="https://www.merl.com/publications/docs/TR2024-066.pdf">PDF</a></li>
<li>R. Korekata, M. Kambara, Y. Yoshida, S. Ishikawa, Y. Kawasaki, M. Takahashi and K. Sugiura, “Switching Head–Tail Funnel UNITER for Dual Referring Expression Comprehension with Fetch-and-Carry Tasks”, IEEE/RSJ IROS, 2023. <a href="https://arxiv.org/pdf/2307.07166.pdf">PDF</a></li>
<li>K. Kaneda, R. Korekata, Y. Wada, S. Nagashima, M. Kambara, Y. Iioka, H. Matsuo, Y. Imai, T. Nishimura, and K. Sugiura, “DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial Training”, CVPR 2023 Embodied AI Workshop, 2023. <a href="https://embodied-ai.org/papers/2023/23.pdf">PDF</a></li>
<li>M. Kambara and K. Sugiura, “Fully Automated Task Management for Generation, Execution, and Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language Instructions in Continuous Space”, CVPR 2023 Embodied AI Workshop, 2023. <a href="https://embodied-ai.org/papers/2023/6.pdf">PDF</a></li>
<li>M. Kambara, K.Sugiura, “Relational Future Captioning Model for Explaining Likely Collisions in Daily Tasks”, IEEE ICIP, TP-V2.V13.14, 2022. <a href="https://arxiv.org/pdf/2207.09083.pdf">PDF</a></li>
<li>M. Kambara and K. Sugiura, “Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions”, IEEE RAL presented at IEEE/RSJ IROS, 2021. <a href="https://arxiv.org/pdf/2107.00789.pdf">PDF</a></li>
</ol>

					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/award/" rel="bookmark">Award</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>K. Kaneda, R. Korekata, Y. Wada, S. Nagashima, M. Kambara, Y. Iioka, H. Matsuo, Y. Imai, T. Nishimura, K. Sugiura, CVPR 2023 Embodied AI Workshop DialFRED Challenge 1st Prize, 6/19/2023.</li>
<li>M. Kambara, Y. Yoshida, K. Kaneda, S. Otsuki, R. Korekata, H. Matsuo, Y. Wada, W. Yang, K. Sugiura, Honorable Mention Award, REVERIE Challenge @ CSIG 2022, 8/19/2022.</li>
</ol>

					</div>
				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
               <span class="posted-on">
                  <time class="entry-date published" datetime="Nov., 1010">
                  
                  </time>
               </span>
						</div>
						<h1 class="entry-title">
						  <a href="https://motonarikambara.github.io/publications/domestic_conf/" rel="bookmark">Domestic Conference</a>
						</h1>
					</header>
					<div class="entry-content">
						<ol>
<li>勝又圭, 神原元就, 八島大地, 是方諒介, 杉浦孔明: “物体操作指示文生成モデルに基づくモバイルマニピュレーションのためのデータセット拡張”, 2025年度 人工知能学会全国大会, 1Win4-49, 2025.</li>
<li>後神美結, 神原元就, 齋藤大地, 小槻誠太郎, 杉浦孔明: “多階層アラインメント視覚表現に基づくリアルタイム物体操作タスク成功判定”, 2025年度 人工知能学会全国大会, 1Win4-51, 2025.</li>
<li>神原元就, 杉浦孔明: “深層状態空間モデルおよびtransformerの並列機構による物体操作前アラインメント予測”, 2025年度 人工知能学会全国大会, 1Win4-55, 2025.</li>
<li>神原元就, 杉浦孔明: “オフライン軌道生成による軌道に基づくopen-vocabulary物体操作タスクにおける将来成否予測”, 第42回日本ロボット学会学術講演会, 3D1-06, 2024.</li>
<li>勝又圭, 神原元就, 杉浦孔明: “自動評価尺度を用いた強化学習およびマルチモーダル基盤モデルに基づく物体操作指示文生成”, 第42回日本ロボット学会学術講演会, 3D3-03, 2024.</li>
<li>後神美結, 神原元就, 小槻誠太郎, 杉浦孔明: “マルチモーダルLLM及び視覚言語基盤モデルに基づく多階層アラインメント表現による物体操作タスク成功判定”, 第42回日本ロボット学会学術講演会, 1D2-07, 2024.</li>
<li>松尾榛夏, 神原元就, 杉浦孔明: “マルチモーダル基盤モデルと劣モジュラ最適化に基づく移動ロボットの環境探索”, 2024年度 人工知能学会全国大会, 4O3-OS-16e-03, 2024.</li>
<li>齋藤大地, 神原元就, 九曜克之, 杉浦孔明: “マルチモーダルLLMおよび視覚言語基盤モデルに基づく大規模物体操作データセットにおけるタスク成功判定”, 2024年度 人工知能学会全国大会, 3O1-OS-16b-02, 2024.</li>
<li>西村喬行, 九曜克之, 神原元就, 杉浦孔明: “マルチモーダル基盤モデルと最適輸送を用いたポリゴンマッチングによる参照表現セグメンテーション”, 2024年度 人工知能学会全国大会, 2O6-OS-16a-02, 2024.</li>
<li>平野慎之助, 小松拓実, 和田唯我, 神原元就, 畑中駿平, 平川翼, 山下隆義, 藤吉弘亘, 杉浦孔明: “ENCHANT: 大規模言語モデルを用いた仮説生成に基づくクロスモーダル説明文生成”, 第41回日本ロボット学会学術講演会, 1K4-03, 2023.</li>
<li>神原元就, 杉浦孔明: “マルチモーダル言語処理に基づくfetch-and-carryタスクの自動化と実行”, 2023年度 人工知能学会全国大会, 2I6-OS-4a-03, 2023.</li>
<li>兼田寛大, 神原元就, 杉浦孔明: “Learning to Rank Physical Objects: ランキング学習による物理世界検索エンジン”, 2023年度 人工知能学会全国大会, 3G1-OS-24a-01, 2023.</li>
<li>小松拓実, 神原元就, 畑中駿平, 松尾榛夏, 平川翼, 山下隆義, 藤吉弘亘, 杉浦孔明: “Nearest Neighbor Future Captioning:物体配置タスクにおける衝突リスクに関する説明文生成”, 2023年度 人工知能学会全国大会, 3G1-OS-24a-05, 2023.</li>
<li>是方諒介, 神原元就, 吉田悠, 石川慎太朗, 川崎陽祐, 髙橋正樹, 杉浦孔明: “Switching Head–Tail Funnel UNITERによる対象物体および配置目標に関する指示文理解と物体操作”, 2023年度 人工知能学会全国大会, 2G4-OS-21d-01, 2023.</li>
<li>神原元就, 杉浦孔明: “記号接地されたfetch-and-carryタスクの自動化と実行”, 第40回日本ロボット学会学術講演会, 4I1-01, 2022.</li>
<li>飯岡雄偉, 神原元就, 杉浦孔明: “物体配置タスクにおける危険性のクロスモーダル説明生成”, 第40回日本ロボット学会学術講演会, 4I1-08, 2022.</li>
<li>神原元就, 杉浦孔明: “日常タスクにおける将来イベントのクロスモーダル説明文生成”, 2022年度 人工知能学会全国大会, 2O1-GS-7-02, 2022.</li>
<li>神原元就, 杉浦孔明: “料理タスクにおける将来イベントのクロスモーダル説明文生成”, 第28回画像センシングシンポジウム 2022, SO3-24・IS3-24, 2022.</li>
<li>兼田寛大, 神原元就, 杉浦孔明: “Bilingual Case Relation Transformerに基づく複数言語による物体操作指示文生成”, 第39回日本ロボット学会学術講演会, 1I2-06, 2021.</li>
<li>神原元就, 杉浦孔明: “Case Relation Transformerに基づく対象物体及び目標領域の参照表現を含む物体操作指示文生成”, 2021年度 人工知能学会全国大会, 4J1-GS-6d-05, 2021.</li>
</ol>

					</div>
				</article>
        
			</div>
		</div>

		<center class="">
			<ul class="pagination">
        
			</ul>
		</center>
	</div>	

</main>

    
    
      <footer id="footer">
	<div class="container">
		<div class="row">
			
			<div class="col-md-3 widget">
				<h3 class="widget-title"></h3>
				<div class="widget-body">
					<p>
					
					<br>
					
					</p>
				</div>
			</div>
			

			
			<div class="col-md-3 widget">
				<h3 class="widget-title"></h3>
				<div class="widget-body">
					<p class="follow-me-icons">
            
							
								<a href="https://twitter.com/MotonariKambara" target="_blank"><i class="fab fa-x-twitter fa-1x"></i></a>
							
            
							
								<a href="https://jp.linkedin.com/in/motonari-kambara-3a9330280" target="_blank"><i class="fab fa-linkedin fa-1x"></i></a>
							
            
							
								<a href="https://github.com/motonarikambara" target="_blank"><i class="fab fa-github fa-1x"></i></a>
							
            
							
								<a href="motonari.k714@keio.jp" target="_blank"><i class="fas fa-envelope fa-1x"></i></a>
							
            
					</p>
				</div>
			</div>
			

			

			

		</div> 
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p></p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
                                                
                                                Copyright &copy; , Motonari Kambara<br>
                                                
						Design: <a href="http://www.gettemplate.com" rel="designer">Initio by GetTemplate</a> -
						Powered by: <a href="https://gohugo.io/" rel="poweredby">Hugo</a>
					</p>
				</div>
			</div>

		</div> 
	</div>
</footer>




<script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>




<script src="https://motonarikambara.github.io/js/bundle.min.8adc00f11fb328590a42ed3b14d3ec5b116abb98395a8a662d782f2150a7de6cc85eacb26c14724bb0c5130a11be2933c9b4f835cd3a053e90f036e210fbdd5d.js" integrity="sha512-itwA8R&#43;zKFkKQu07FNPsWxFqu5g5WopmLXgvIVCn3mzIXqyybBRyS7DFEwoRvikzybT4Nc06BT6Q8DbiEPvdXQ=="></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-3R7Q5YFDBK', 'auto');
  ga('send', 'pageview');
</script>

</body>
</html>

    
  </body>
  
</html>